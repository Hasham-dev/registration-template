{"ast":null,"code":"import { __assign } from \"tslib\";\nimport { invariant, InvariantError } from 'ts-invariant';\nimport { equal } from '@wry/equality';\nimport { createFragmentMap, getFragmentFromSelection, getDefaultValues, getFragmentDefinitions, getOperationDefinition, getTypenameFromResult, makeReference, isField, resultKeyNameFromField, isReference, shouldInclude, hasDirectives, cloneDeep } from \"../../utilities/index.js\";\nimport { makeProcessedFieldsMerger, fieldNameFromStoreName, storeValueIsStoreObject } from \"./helpers.js\";\n;\nvar StoreWriter = function () {\n  function StoreWriter(cache, reader) {\n    this.cache = cache;\n    this.reader = reader;\n  }\n  StoreWriter.prototype.writeToStore = function (_a) {\n    var query = _a.query,\n      result = _a.result,\n      dataId = _a.dataId,\n      store = _a.store,\n      variables = _a.variables;\n    var operationDefinition = getOperationDefinition(query);\n    var merger = makeProcessedFieldsMerger();\n    variables = __assign(__assign({}, getDefaultValues(operationDefinition)), variables);\n    var ref = this.processSelectionSet({\n      result: result || Object.create(null),\n      dataId: dataId,\n      selectionSet: operationDefinition.selectionSet,\n      mergeTree: {\n        map: new Map()\n      },\n      context: {\n        store: store,\n        written: Object.create(null),\n        merge: function merge(existing, incoming) {\n          return merger.merge(existing, incoming);\n        },\n        variables: variables,\n        varString: JSON.stringify(variables),\n        fragmentMap: createFragmentMap(getFragmentDefinitions(query))\n      }\n    });\n    if (!isReference(ref)) {\n      throw process.env.NODE_ENV === \"production\" ? new InvariantError(7) : new InvariantError(\"Could not identify object \" + JSON.stringify(result));\n    }\n    store.retain(ref.__ref);\n    return ref;\n  };\n  StoreWriter.prototype.processSelectionSet = function (_a) {\n    var _this = this;\n    var dataId = _a.dataId,\n      result = _a.result,\n      selectionSet = _a.selectionSet,\n      context = _a.context,\n      mergeTree = _a.mergeTree;\n    var policies = this.cache.policies;\n    var _b = policies.identify(result, selectionSet, context.fragmentMap),\n      id = _b[0],\n      keyObject = _b[1];\n    dataId = dataId || id;\n    if (\"string\" === typeof dataId) {\n      var sets = context.written[dataId] || (context.written[dataId] = []);\n      var ref = makeReference(dataId);\n      if (sets.indexOf(selectionSet) >= 0) return ref;\n      sets.push(selectionSet);\n      if (this.reader && this.reader.isFresh(result, ref, selectionSet, context)) {\n        return ref;\n      }\n    }\n    var incomingFields = Object.create(null);\n    if (keyObject) {\n      incomingFields = context.merge(incomingFields, keyObject);\n    }\n    var typename = dataId && policies.rootTypenamesById[dataId] || getTypenameFromResult(result, selectionSet, context.fragmentMap) || dataId && context.store.get(dataId, \"__typename\");\n    if (\"string\" === typeof typename) {\n      incomingFields.__typename = typename;\n    }\n    var workSet = new Set(selectionSet.selections);\n    workSet.forEach(function (selection) {\n      var _a;\n      if (!shouldInclude(selection, context.variables)) return;\n      if (isField(selection)) {\n        var resultFieldKey = resultKeyNameFromField(selection);\n        var value = result[resultFieldKey];\n        if (typeof value !== 'undefined') {\n          var storeFieldName = policies.getStoreFieldName({\n            typename: typename,\n            fieldName: selection.name.value,\n            field: selection,\n            variables: context.variables\n          });\n          var childTree = getChildMergeTree(mergeTree, storeFieldName);\n          var incomingValue = _this.processFieldValue(value, selection, context, childTree);\n          var childTypename = selection.selectionSet && context.store.getFieldValue(incomingValue, \"__typename\") || void 0;\n          var merge = policies.getMergeFunction(typename, selection.name.value, childTypename);\n          if (merge) {\n            childTree.info = {\n              field: selection,\n              typename: typename,\n              merge: merge\n            };\n          } else {\n            maybeRecycleChildMergeTree(mergeTree, storeFieldName);\n          }\n          incomingFields = context.merge(incomingFields, (_a = {}, _a[storeFieldName] = incomingValue, _a));\n        } else if (policies.usingPossibleTypes && !hasDirectives([\"defer\", \"client\"], selection)) {\n          throw process.env.NODE_ENV === \"production\" ? new InvariantError(8) : new InvariantError(\"Missing field '\" + resultFieldKey + \"' in \" + JSON.stringify(result, null, 2).substring(0, 100));\n        }\n      } else {\n        var fragment = getFragmentFromSelection(selection, context.fragmentMap);\n        if (fragment && policies.fragmentMatches(fragment, typename, result, context.variables)) {\n          fragment.selectionSet.selections.forEach(workSet.add, workSet);\n        }\n      }\n    });\n    if (\"string\" === typeof dataId) {\n      var entityRef_1 = makeReference(dataId);\n      if (mergeTree.map.size) {\n        incomingFields = this.applyMerges(mergeTree, entityRef_1, incomingFields, context);\n      }\n      if (process.env.NODE_ENV !== \"production\") {\n        var hasSelectionSet_1 = function hasSelectionSet_1(storeFieldName) {\n          return fieldsWithSelectionSets_1.has(fieldNameFromStoreName(storeFieldName));\n        };\n        var fieldsWithSelectionSets_1 = new Set();\n        workSet.forEach(function (selection) {\n          if (isField(selection) && selection.selectionSet) {\n            fieldsWithSelectionSets_1.add(selection.name.value);\n          }\n        });\n        var hasMergeFunction_1 = function hasMergeFunction_1(storeFieldName) {\n          var childTree = mergeTree.map.get(storeFieldName);\n          return Boolean(childTree && childTree.info && childTree.info.merge);\n        };\n        Object.keys(incomingFields).forEach(function (storeFieldName) {\n          if (hasSelectionSet_1(storeFieldName) && !hasMergeFunction_1(storeFieldName)) {\n            warnAboutDataLoss(entityRef_1, incomingFields, storeFieldName, context.store);\n          }\n        });\n      }\n      context.store.merge(dataId, incomingFields);\n      return entityRef_1;\n    }\n    return incomingFields;\n  };\n  StoreWriter.prototype.processFieldValue = function (value, field, context, mergeTree) {\n    var _this = this;\n    if (!field.selectionSet || value === null) {\n      return process.env.NODE_ENV === 'production' ? value : cloneDeep(value);\n    }\n    if (Array.isArray(value)) {\n      return value.map(function (item, i) {\n        var value = _this.processFieldValue(item, field, context, getChildMergeTree(mergeTree, i));\n        maybeRecycleChildMergeTree(mergeTree, i);\n        return value;\n      });\n    }\n    return this.processSelectionSet({\n      result: value,\n      selectionSet: field.selectionSet,\n      context: context,\n      mergeTree: mergeTree\n    });\n  };\n  StoreWriter.prototype.applyMerges = function (mergeTree, existing, incoming, context, getStorageArgs) {\n    var _a;\n    var _this = this;\n    if (mergeTree.map.size && !isReference(incoming)) {\n      var e_1 = !Array.isArray(incoming) && (isReference(existing) || storeValueIsStoreObject(existing)) ? existing : void 0;\n      var i_1 = incoming;\n      if (e_1 && !getStorageArgs) {\n        getStorageArgs = [isReference(e_1) ? e_1.__ref : e_1];\n      }\n      var changedFields_1;\n      var getValue_1 = function getValue_1(from, name) {\n        return Array.isArray(from) ? typeof name === \"number\" ? from[name] : void 0 : context.store.getFieldValue(from, String(name));\n      };\n      mergeTree.map.forEach(function (childTree, storeFieldName) {\n        if (getStorageArgs) {\n          getStorageArgs.push(storeFieldName);\n        }\n        var eVal = getValue_1(e_1, storeFieldName);\n        var iVal = getValue_1(i_1, storeFieldName);\n        var aVal = _this.applyMerges(childTree, eVal, iVal, context, getStorageArgs);\n        if (aVal !== iVal) {\n          changedFields_1 = changedFields_1 || new Map();\n          changedFields_1.set(storeFieldName, aVal);\n        }\n        if (getStorageArgs) {\n          invariant(getStorageArgs.pop() === storeFieldName);\n        }\n      });\n      if (changedFields_1) {\n        incoming = Array.isArray(i_1) ? i_1.slice(0) : __assign({}, i_1);\n        changedFields_1.forEach(function (value, name) {\n          incoming[name] = value;\n        });\n      }\n    }\n    if (mergeTree.info) {\n      return this.cache.policies.runMergeFunction(existing, incoming, mergeTree.info, context, getStorageArgs && (_a = context.store).getStorage.apply(_a, getStorageArgs));\n    }\n    return incoming;\n  };\n  return StoreWriter;\n}();\nexport { StoreWriter };\nvar emptyMergeTreePool = [];\nfunction getChildMergeTree(_a, name) {\n  var map = _a.map;\n  if (!map.has(name)) {\n    map.set(name, emptyMergeTreePool.pop() || {\n      map: new Map()\n    });\n  }\n  return map.get(name);\n}\nfunction maybeRecycleChildMergeTree(_a, name) {\n  var map = _a.map;\n  var childTree = map.get(name);\n  if (childTree && !childTree.info && !childTree.map.size) {\n    emptyMergeTreePool.push(childTree);\n    map.delete(name);\n  }\n}\nvar warnings = new Set();\nfunction warnAboutDataLoss(existingRef, incomingObj, storeFieldName, store) {\n  var getChild = function getChild(objOrRef) {\n    var child = store.getFieldValue(objOrRef, storeFieldName);\n    return typeof child === \"object\" && child;\n  };\n  var existing = getChild(existingRef);\n  if (!existing) return;\n  var incoming = getChild(incomingObj);\n  if (!incoming) return;\n  if (isReference(existing)) return;\n  if (equal(existing, incoming)) return;\n  if (Object.keys(existing).every(function (key) {\n    return store.getFieldValue(incoming, key) !== void 0;\n  })) {\n    return;\n  }\n  var parentType = store.getFieldValue(existingRef, \"__typename\") || store.getFieldValue(incomingObj, \"__typename\");\n  var fieldName = fieldNameFromStoreName(storeFieldName);\n  var typeDotName = parentType + \".\" + fieldName;\n  if (warnings.has(typeDotName)) return;\n  warnings.add(typeDotName);\n  var childTypenames = [];\n  if (!Array.isArray(existing) && !Array.isArray(incoming)) {\n    [existing, incoming].forEach(function (child) {\n      var typename = store.getFieldValue(child, \"__typename\");\n      if (typeof typename === \"string\" && !childTypenames.includes(typename)) {\n        childTypenames.push(typename);\n      }\n    });\n  }\n  process.env.NODE_ENV === \"production\" || invariant.warn(\"Cache data may be lost when replacing the \" + fieldName + \" field of a \" + parentType + \" object.\\n\\nTo address this problem (which is not a bug in Apollo Client), \" + (childTypenames.length ? \"either ensure all objects of type \" + childTypenames.join(\" and \") + \" have an ID or a custom merge function, or \" : \"\") + \"define a custom merge function for the \" + typeDotName + \" field, so InMemoryCache can safely merge these objects:\\n\\n  existing: \" + JSON.stringify(existing).slice(0, 1000) + \"\\n  incoming: \" + JSON.stringify(incoming).slice(0, 1000) + \"\\n\\nFor more information about these options, please refer to the documentation:\\n\\n  * Ensuring entity objects have IDs: https://go.apollo.dev/c/generating-unique-identifiers\\n  * Defining custom merge functions: https://go.apollo.dev/c/merging-non-normalized-objects\\n\");\n}","map":{"version":3,"sources":["../../../src/cache/inmemory/writeToStore.ts"],"names":[],"mappings":";AACA,SAAS,SAAS,EAAE,cAAc,QAAQ,cAAc;AACxD,SAAS,KAAK,QAAQ,eAAe;AAErC,SACE,iBAAiB,EAEjB,wBAAwB,EACxB,gBAAgB,EAChB,sBAAsB,EACtB,sBAAsB,EACtB,qBAAqB,EACrB,aAAa,EACb,OAAO,EACP,sBAAsB,EAItB,WAAW,EACX,aAAa,EACb,aAAa,EACb,SAAS,QACJ,0BAAkB;AAGzB,SAAS,yBAAyB,EAAE,sBAAsB,EAAE,uBAAuB,QAAQ,cAAY;AAYtG;AAkBD,IAAA,WAAA,GAAA,YAAA;EACE,SAAA,WAAA,CACkB,KAAoB,EAC5B,MAAoB,EAAA;IADZ,IAAA,CAAA,KAAK,GAAL,KAAK;IACb,IAAA,CAAA,MAAM,GAAN,MAAM;EACb;EAgBI,WAAA,CAAA,SAAA,CAAA,YAAY,GAAnB,UAAoB,EAME,EAAA;QALpB,KAAK,GAAA,EAAA,CAAA,KAAA;MACL,MAAM,GAAA,EAAA,CAAA,MAAA;MACN,MAAM,GAAA,EAAA,CAAA,MAAA;MACN,KAAK,GAAA,EAAA,CAAA,KAAA;MACL,SAAS,GAAA,EAAA,CAAA,SAAA;IAET,IAAM,mBAAmB,GAAG,sBAAsB,CAAC,KAAK,CAAE;IAC1D,IAAM,MAAM,GAAG,yBAAyB,EAAE;IAE1C,SAAS,GAAA,QAAA,CAAA,QAAA,CAAA,CAAA,CAAA,EACJ,gBAAgB,CAAC,mBAAmB,CAAC,CAAA,EACrC,SAAU,CACd;IAED,IAAM,GAAG,GAAG,IAAI,CAAC,mBAAmB,CAAC;MACnC,MAAM,EAAE,MAAM,IAAI,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC;MACrC,MAAM,EAAA,MAAA;MACN,YAAY,EAAE,mBAAmB,CAAC,YAAY;MAC9C,SAAS,EAAE;QAAE,GAAG,EAAE,IAAI,GAAG;MAAA,CAAE;MAC3B,OAAO,EAAE;QACP,KAAK,EAAA,KAAA;QACL,OAAO,EAAE,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC;QAC5B,KAAK,EAAL,eAAS,QAAW,EAAE,QAAW,EAAA;UAC/B,OAAO,MAAM,CAAC,KAAK,CAAC,QAAQ,EAAE,QAAQ,CAAM;QAC9C,CAAC;QACD,SAAS,EAAA,SAAA;QACT,SAAS,EAAE,IAAI,CAAC,SAAS,CAAC,SAAS,CAAC;QACpC,WAAW,EAAE,iBAAiB,CAAC,sBAAsB,CAAC,KAAK,CAAC;MAC7D;KACF,CAAC;IAEF,IAAI,CAAC,WAAW,CAAC,GAAG,CAAC,EAAE;MACrB,MAAM,OAAI,CAAA,GAAA,CAAA,QAAe,KAAA,YAAA,GAAA,IAAA,cAAkC,CAAA,CAAA,CAAA,GAAS,IAAC,cAAW,CAAA,4BAAA,GAAA,IAAA,CAAA,SAAA,CAAA,MAAA,CAAA,CAAA;IACjF;IAOD,KAAK,CAAC,MAAM,CAAC,GAAG,CAAC,KAAK,CAAC;IAEvB,OAAO,GAAG;EACZ,CAAC;EAEO,WAAA,CAAA,SAAA,CAAA,mBAAmB,GAA3B,UAA4B,EAQC,EAAA;IAR7B,IAAA,KAAA,GAAA,IAAA;QACE,MAAM,GAAA,EAAA,CAAA,MAAA;MACN,MAAM,GAAA,EAAA,CAAA,MAAA;MACN,YAAY,GAAA,EAAA,CAAA,YAAA;MACZ,OAAO,GAAA,EAAA,CAAA,OAAA;MAGP,SAAS,GAAA,EAAA,CAAA,SAAA;IAED,IAAA,QAAQ,GAAK,IAAI,CAAC,KAAK,CAAA,QAAf;IAIV,IAAA,EAAA,GAAkB,QAAQ,CAAC,QAAQ,CACvC,MAAM,EAAE,YAAY,EAAE,OAAO,CAAC,WAAW,CAAC;MADrC,EAAE,GAAA,EAAA,CAAA,CAAA,CAAA;MAAE,SAAS,GAAA,EAAA,CAAA,CAAA,CACwB;IAI5C,MAAM,GAAG,MAAM,IAAI,EAAE;IAErB,IAAI,QAAQ,KAAK,OAAO,MAAM,EAAE;MAM9B,IAAM,IAAI,GAAG,OAAO,CAAC,OAAO,CAAC,MAAM,CAAC,KAAK,OAAO,CAAC,OAAO,CAAC,MAAM,CAAC,GAAG,EAAE,CAAC;MACtE,IAAM,GAAG,GAAG,aAAa,CAAC,MAAM,CAAC;MACjC,IAAI,IAAI,CAAC,OAAO,CAAC,YAAY,CAAC,IAAI,CAAC,EAAE,OAAO,GAAG;MAC/C,IAAI,CAAC,IAAI,CAAC,YAAY,CAAC;MAOvB,IAAI,IAAI,CAAC,MAAM,IAAI,IAAI,CAAC,MAAM,CAAC,OAAO,CACpC,MAAM,EACN,GAAG,EACH,YAAY,EACZ,OAAO,CACR,EAAE;QACD,OAAO,GAAG;MACX;IACF;IAID,IAAI,cAAc,GAAgB,MAAM,CAAC,MAAM,CAAC,IAAI,CAAC;IAIrD,IAAI,SAAS,EAAE;MACb,cAAc,GAAG,OAAO,CAAC,KAAK,CAAC,cAAc,EAAE,SAAS,CAAC;IAC1D;IAKD,IAAM,QAAQ,GACX,MAAM,IAAI,QAAQ,CAAC,iBAAiB,CAAC,MAAM,CAAC,IAC7C,qBAAqB,CAAC,MAAM,EAAE,YAAY,EAAE,OAAO,CAAC,WAAW,CAAC,IAC/D,MAAM,IAAI,OAAO,CAAC,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE,YAAY,CAAY;IAE/D,IAAI,QAAQ,KAAK,OAAO,QAAQ,EAAE;MAChC,cAAc,CAAC,UAAU,GAAG,QAAQ;IACrC;IAED,IAAM,OAAO,GAAG,IAAI,GAAG,CAAC,YAAY,CAAC,UAAU,CAAC;IAEhD,OAAO,CAAC,OAAO,CAAC,UAAA,SAAS,EAAA;;MACvB,IAAI,CAAC,aAAa,CAAC,SAAS,EAAE,OAAO,CAAC,SAAS,CAAC,EAAE;MAElD,IAAI,OAAO,CAAC,SAAS,CAAC,EAAE;QACtB,IAAM,cAAc,GAAG,sBAAsB,CAAC,SAAS,CAAC;QACxD,IAAM,KAAK,GAAG,MAAM,CAAC,cAAc,CAAC;QAEpC,IAAI,OAAO,KAAK,KAAK,WAAW,EAAE;UAChC,IAAM,cAAc,GAAG,QAAQ,CAAC,iBAAiB,CAAC;YAChD,QAAQ,EAAA,QAAA;YACR,SAAS,EAAE,SAAS,CAAC,IAAI,CAAC,KAAK;YAC/B,KAAK,EAAE,SAAS;YAChB,SAAS,EAAE,OAAO,CAAC;WACpB,CAAC;UAEF,IAAM,SAAS,GAAG,iBAAiB,CAAC,SAAS,EAAE,cAAc,CAAC;UAE9D,IAAI,aAAa,GACf,KAAI,CAAC,iBAAiB,CAAC,KAAK,EAAE,SAAS,EAAE,OAAO,EAAE,SAAS,CAAC;UAE9D,IAAM,aAAa,GAAG,SAAS,CAAC,YAAY,IACvC,OAAO,CAAC,KAAK,CAAC,aAAa,CAAS,aAA4B,EAAE,YAAY,CAAC,IAC/E,KAAK,CAAC;UAEX,IAAM,KAAK,GAAG,QAAQ,CAAC,gBAAgB,CACrC,QAAQ,EACR,SAAS,CAAC,IAAI,CAAC,KAAK,EACpB,aAAa,CACd;UAED,IAAI,KAAK,EAAE;YACT,SAAS,CAAC,IAAI,GAAG;cAGf,KAAK,EAAE,SAAS;cAChB,QAAQ,EAAA,QAAA;cACR,KAAK,EAAA;aACN;WACF,MAAM;YACL,0BAA0B,CAAC,SAAS,EAAE,cAAc,CAAC;UACtD;UAED,cAAc,GAAG,OAAO,CAAC,KAAK,CAAC,cAAc,GAAA,EAAA,GAAA,CAAA,CAAA,EAC3C,EAAA,CAAC,cAAc,CAAA,GAAG,aAAa,E,IAC/B;SAEH,MAAM,IACL,QAAQ,CAAC,kBAAkB,IAC3B,CAAC,aAAa,CAAC,CAAC,OAAO,EAAE,QAAQ,CAAC,EAAE,SAAS,CAAC,EAC9C;UACA,MAAM,OAAI,CAAA,GAAA,CAAA,QACR,KAAA,YAAA,GAAkB,IAAA,cAAc,CAAA,CAAA,CAAA,GAAA,IAAQ,cACtC,CAAA,iBAGA,GAAA,cACF,GAAA,OAAA,GAAA,IAAA,CAAA,SAAA,CAAA,MAAA,EAAA,IAAA,EAAA,CAAA,CAAA,CAAA,SAAA,CAAA,CAAA,EAAA,GAAA,CAAA,CAAA;QACH;OACF,MAAM;QAEL,IAAM,QAAQ,GAAG,wBAAwB,CACvC,SAAS,EACT,OAAO,CAAC,WAAW,CACpB;QAED,IAAI,QAAQ,IAmBR,QAAQ,CAAC,eAAe,CAAC,QAAQ,EAAE,QAAQ,EAAE,MAAM,EAAE,OAAO,CAAC,SAAS,CAAC,EAAE;UAC3E,QAAQ,CAAC,YAAY,CAAC,UAAU,CAAC,OAAO,CAAC,OAAO,CAAC,GAAG,EAAE,OAAO,CAAC;QAC/D;MACF;IACH,CAAC,CAAC;IAEF,IAAI,QAAQ,KAAK,OAAO,MAAM,EAAE;MAC9B,IAAM,WAAS,GAAG,aAAa,CAAC,MAAM,CAAC;MAEvC,IAAI,SAAS,CAAC,GAAG,CAAC,IAAI,EAAE;QACtB,cAAc,GAAG,IAAI,CAAC,WAAW,CAAC,SAAS,EAAE,WAAS,EAAE,cAAc,EAAE,OAAO,CAAC;MACjF;MAED,IAAI,OAAO,CAAC,GAAG,CAAC,QAAQ,KAAK,YAAY,EAAE;QACzC,IAAM,iBAAe,GAAG,SAAlB,iBAAe,CAAI,cAAsB,EAAA;UAC7C,OAAA,yBAAuB,CAAC,GAAG,CAAC,sBAAsB,CAAC,cAAc,CAAC,CAAC;QAAnE,CAAmE;QACrE,IAAM,yBAAuB,GAAG,IAAI,GAAG,EAAU;QACjD,OAAO,CAAC,OAAO,CAAC,UAAA,SAAS,EAAA;UACvB,IAAI,OAAO,CAAC,SAAS,CAAC,IAAI,SAAS,CAAC,YAAY,EAAE;YAChD,yBAAuB,CAAC,GAAG,CAAC,SAAS,CAAC,IAAI,CAAC,KAAK,CAAC;UAClD;QACH,CAAC,CAAC;QAEF,IAAM,kBAAgB,GAAG,SAAnB,kBAAgB,CAAI,cAAsB,EAAA;UAC9C,IAAM,SAAS,GAAG,SAAS,CAAC,GAAG,CAAC,GAAG,CAAC,cAAc,CAAC;UACnD,OAAO,OAAO,CAAC,SAAS,IAAI,SAAS,CAAC,IAAI,IAAI,SAAS,CAAC,IAAI,CAAC,KAAK,CAAC;QACrE,CAAC;QAED,MAAM,CAAC,IAAI,CAAC,cAAc,CAAC,CAAC,OAAO,CAAC,UAAA,cAAc,EAAA;UAKhD,IAAI,iBAAe,CAAC,cAAc,CAAC,IAC/B,CAAC,kBAAgB,CAAC,cAAc,CAAC,EAAE;YACrC,iBAAiB,CACf,WAAS,EACT,cAAc,EACd,cAAc,EACd,OAAO,CAAC,KAAK,CACd;UACF;QACH,CAAC,CAAC;MACH;MAED,OAAO,CAAC,KAAK,CAAC,KAAK,CAAC,MAAM,EAAE,cAAc,CAAC;MAE3C,OAAO,WAAS;IACjB;IAED,OAAO,cAAc;EACvB,CAAC;EAEO,WAAA,CAAA,SAAA,CAAA,iBAAiB,GAAzB,UACE,KAAU,EACV,KAAgB,EAChB,OAAqB,EACrB,SAAoB,EAAA;IAJtB,IAAA,KAAA,GAAA,IAAA;IAME,IAAI,CAAC,KAAK,CAAC,YAAY,IAAI,KAAK,KAAK,IAAI,EAAE;MAIzC,OAAO,OAAO,CAAC,GAAG,CAAC,QAAQ,KAAK,YAAY,GAAG,KAAK,GAAG,SAAS,CAAC,KAAK,CAAC;IACxE;IAED,IAAI,KAAK,CAAC,OAAO,CAAC,KAAK,CAAC,EAAE;MACxB,OAAO,KAAK,CAAC,GAAG,CAAC,UAAC,IAAI,EAAE,CAAC,EAAA;QACvB,IAAM,KAAK,GAAG,KAAI,CAAC,iBAAiB,CAClC,IAAI,EAAE,KAAK,EAAE,OAAO,EAAE,iBAAiB,CAAC,SAAS,EAAE,CAAC,CAAC,CAAC;QACxD,0BAA0B,CAAC,SAAS,EAAE,CAAC,CAAC;QACxC,OAAO,KAAK;MACd,CAAC,CAAC;IACH;IAED,OAAO,IAAI,CAAC,mBAAmB,CAAC;MAC9B,MAAM,EAAE,KAAK;MACb,YAAY,EAAE,KAAK,CAAC,YAAY;MAChC,OAAO,EAAA,OAAA;MACP,SAAS,EAAA;KACV,CAAC;EACJ,CAAC;EAEO,WAAA,CAAA,SAAA,CAAA,WAAW,GAAnB,UACE,SAAoB,EACpB,QAAoB,EACpB,QAAW,EACX,OAA+B,EAC/B,cAAsD,EAAA;;IALxD,IAAA,KAAA,GAAA,IAAA;IAOE,IAAI,SAAS,CAAC,GAAG,CAAC,IAAI,IAAI,CAAC,WAAW,CAAC,QAAQ,CAAC,EAAE;MAChD,IAAM,GAAC,GAIL,CAAC,KAAK,CAAC,OAAO,CAAC,QAAQ,CAAC,KAIvB,WAAW,CAAC,QAAQ,CAAC,IAAI,uBAAuB,CAAC,QAAQ,CAAC,CAAC,GAC1D,QAAQ,GAAG,KAAK,CAAC;MAKrB,IAAM,GAAC,GAAG,QAAsC;MAMhD,IAAI,GAAC,IAAI,CAAC,cAAc,EAAE;QACxB,cAAc,GAAG,CAAC,WAAW,CAAC,GAAC,CAAC,GAAG,GAAC,CAAC,KAAK,GAAG,GAAC,CAAC;MAChD;MAOD,IAAI,eAA2D;MAE/D,IAAM,UAAQ,GAAG,SAAX,UAAQ,CACZ,IAAyB,EACzB,IAAqB,EAAA;QAErB,OAAO,KAAK,CAAC,OAAO,CAAC,IAAI,CAAC,GACrB,OAAO,IAAI,KAAK,QAAQ,GAAG,IAAI,CAAC,IAAI,CAAC,GAAG,KAAK,CAAC,GAC/C,OAAO,CAAC,KAAK,CAAC,aAAa,CAAC,IAAI,EAAE,MAAM,CAAC,IAAI,CAAC,CAAC;MACrD,CAAC;MAED,SAAS,CAAC,GAAG,CAAC,OAAO,CAAC,UAAC,SAAS,EAAE,cAAc,EAAA;QAC9C,IAAI,cAAc,EAAE;UAClB,cAAc,CAAC,IAAI,CAAC,cAAc,CAAC;QACpC;QACD,IAAM,IAAI,GAAG,UAAQ,CAAC,GAAC,EAAE,cAAc,CAAC;QACxC,IAAM,IAAI,GAAG,UAAQ,CAAC,GAAC,EAAE,cAAc,CAAC;QACxC,IAAM,IAAI,GAAG,KAAI,CAAC,WAAW,CAC3B,SAAS,EACT,IAAI,EACJ,IAAI,EACJ,OAAO,EACP,cAAc,CACf;QACD,IAAI,IAAI,KAAK,IAAI,EAAE;UACjB,eAAa,GAAG,eAAa,IAAI,IAAI,GAAG;UACxC,eAAa,CAAC,GAAG,CAAC,cAAc,EAAE,IAAI,CAAC;QACxC;QACD,IAAI,cAAc,EAAE;UAClB,SAAS,CAAC,cAAc,CAAC,GAAG,EAAE,KAAK,cAAc,CAAC;QACnD;MACH,CAAC,CAAC;MAEF,IAAI,eAAa,EAAE;QAEjB,QAAQ,GAAI,KAAK,CAAC,OAAO,CAAC,GAAC,CAAC,GAAG,GAAC,CAAC,KAAK,CAAC,CAAC,CAAC,GAAE,QAAA,CAAA,CAAA,CAAA,EAAM,GAAC,CAAQ;QAC1D,eAAa,CAAC,OAAO,CAAC,UAAC,KAAK,EAAE,IAAI,EAAA;UAC/B,QAAgB,CAAC,IAAI,CAAC,GAAG,KAAK;QACjC,CAAC,CAAC;MACH;IACF;IAED,IAAI,SAAS,CAAC,IAAI,EAAE;MAClB,OAAO,IAAI,CAAC,KAAK,CAAC,QAAQ,CAAC,gBAAgB,CACzC,QAAQ,EACR,QAAQ,EACR,SAAS,CAAC,IAAI,EACd,OAAO,EACP,cAAc,IAAI,CAAA,EAAA,GAAA,OAAO,CAAC,KAAK,EAAC,UAAU,CAAA,KAAA,CAAA,EAAA,EAAI,cAAc,CAAC,CAC9D;IACF;IAED,OAAO,QAAQ;EACjB,CAAC;EACH,OAAA,WAAC;AAAD,CAAC,EAAA;;AAED,IAAM,kBAAkB,GAAgB,EAAE;AAE1C,SAAS,iBAAiB,CACxB,EAAkB,EAClB,IAAqB,EAAA;MADnB,GAAG,GAAA,EAAA,CAAA,GAAA;EAGL,IAAI,CAAC,GAAG,CAAC,GAAG,CAAC,IAAI,CAAC,EAAE;IAClB,GAAG,CAAC,GAAG,CAAC,IAAI,EAAE,kBAAkB,CAAC,GAAG,EAAE,IAAI;MAAE,GAAG,EAAE,IAAI,GAAG;IAAA,CAAE,CAAC;EAC5D;EACD,OAAO,GAAG,CAAC,GAAG,CAAC,IAAI,CAAE;AACvB;AAEA,SAAS,0BAA0B,CACjC,EAAkB,EAClB,IAAqB,EAAA;MADnB,GAAG,GAAA,EAAA,CAAA,GAAA;EAGL,IAAM,SAAS,GAAG,GAAG,CAAC,GAAG,CAAC,IAAI,CAAC;EAC/B,IAAI,SAAS,IACT,CAAC,SAAS,CAAC,IAAI,IACf,CAAC,SAAS,CAAC,GAAG,CAAC,IAAI,EAAE;IACvB,kBAAkB,CAAC,IAAI,CAAC,SAAS,CAAC;IAClC,GAAG,CAAC,MAAM,CAAC,IAAI,CAAC;EACjB;AACH;AAEA,IAAM,QAAQ,GAAG,IAAI,GAAG,EAAU;AAIlC,SAAS,iBAAiB,CACxB,WAAsB,EACtB,WAAwB,EACxB,cAAsB,EACtB,KAAsB,EAAA;EAEtB,IAAM,QAAQ,GAAG,SAAX,QAAQ,CAAI,QAAiC,EAAA;IACjD,IAAM,KAAK,GAAG,KAAK,CAAC,aAAa,CAAc,QAAQ,EAAE,cAAc,CAAC;IACxE,OAAO,OAAO,KAAK,KAAK,QAAQ,IAAI,KAAK;EAC3C,CAAC;EAED,IAAM,QAAQ,GAAG,QAAQ,CAAC,WAAW,CAAC;EACtC,IAAI,CAAC,QAAQ,EAAE;EAEf,IAAM,QAAQ,GAAG,QAAQ,CAAC,WAAW,CAAC;EACtC,IAAI,CAAC,QAAQ,EAAE;EAIf,IAAI,WAAW,CAAC,QAAQ,CAAC,EAAE;EAI3B,IAAI,KAAK,CAAC,QAAQ,EAAE,QAAQ,CAAC,EAAE;EAK/B,IAAI,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,KAAK,CAC7B,UAAA,GAAG,EAAA;IAAI,OAAA,KAAK,CAAC,aAAa,CAAC,QAAQ,EAAE,GAAG,CAAC,KAAK,KAAK,CAAC;EAA7C,CAA6C,CAAC,EAAE;IACvD;EACD;EAED,IAAM,UAAU,GACd,KAAK,CAAC,aAAa,CAAS,WAAW,EAAE,YAAY,CAAC,IACtD,KAAK,CAAC,aAAa,CAAS,WAAW,EAAE,YAAY,CAAC;EACxD,IAAM,SAAS,GAAG,sBAAsB,CAAC,cAAc,CAAC;EACxD,IAAM,WAAW,GAAM,UAAU,GAAA,GAAA,GAAI,SAAW;EAEhD,IAAI,QAAQ,CAAC,GAAG,CAAC,WAAW,CAAC,EAAE;EAC/B,QAAQ,CAAC,GAAG,CAAC,WAAW,CAAC;EAEzB,IAAM,cAAc,GAAa,EAAE;EAGnC,IAAI,CAAC,KAAK,CAAC,OAAO,CAAC,QAAQ,CAAC,IACxB,CAAC,KAAK,CAAC,OAAO,CAAC,QAAQ,CAAC,EAAE;IAC5B,CAAC,QAAQ,EAAE,QAAQ,CAAC,CAAC,OAAO,CAAC,UAAA,KAAK,EAAA;MAChC,IAAM,QAAQ,GAAG,KAAK,CAAC,aAAa,CAAC,KAAK,EAAE,YAAY,CAAC;MACzD,IAAI,OAAO,QAAQ,KAAK,QAAQ,IAC5B,CAAC,cAAc,CAAC,QAAQ,CAAC,QAAQ,CAAC,EAAE;QACtC,cAAc,CAAC,IAAI,CAAC,QAAQ,CAAC;MAC9B;IACH,CAAC,CAAC;EACH;EAED,OAAA,CAAA,GAAU,CAAA,QACZ,KAAA,YAAA,IAAA,SAAA,CAAA,IAAA,CAAA,4CAAqE,GAAU,SAAA,GAAA,cAAA,GAAA,UAAA,GAAA,6EAGxD,IAAA,cAAA,CAAA,MAAA,GACjB,oCAAoC,GAClC,cAAc,CAAC,IAAI,CAAC,OAAO,CAAC,GAAG,6CAA6C,GAC9E,EAAE,CAAA,GAAA,yCAAA,GAEN,WAAW,GAAA,0EAAA,GAGC,IAAI,CAAC,SAAS,CAAC,QAAQ,CAAC,CAAC,KAAK,CAAC,CAAC,EAAE,IAAI,CAAC,GAAA,gBAAA,GACvC,IAAI,CAAC,SAAS,CAAC,QAAQ,CAAC,CAAC,KAAK,CAAC,CAAC,EAAE,IAAI,CAAC,GAAA,gRAMpD,CAAC;AACF","sourcesContent":["import { SelectionSetNode, FieldNode, DocumentNode } from 'graphql';\nimport { invariant, InvariantError } from 'ts-invariant';\nimport { equal } from '@wry/equality';\n\nimport {\n  createFragmentMap,\n  FragmentMap,\n  getFragmentFromSelection,\n  getDefaultValues,\n  getFragmentDefinitions,\n  getOperationDefinition,\n  getTypenameFromResult,\n  makeReference,\n  isField,\n  resultKeyNameFromField,\n  StoreValue,\n  StoreObject,\n  Reference,\n  isReference,\n  shouldInclude,\n  hasDirectives,\n  cloneDeep,\n} from '../../utilities';\n\nimport { NormalizedCache, ReadMergeModifyContext, MergeTree } from './types';\nimport { makeProcessedFieldsMerger, fieldNameFromStoreName, storeValueIsStoreObject } from './helpers';\nimport { StoreReader } from './readFromStore';\nimport { InMemoryCache } from './inMemoryCache';\nimport { EntityStore } from './entityStore';\n\nexport interface WriteContext extends ReadMergeModifyContext {\n  readonly written: {\n    [dataId: string]: SelectionSetNode[];\n  };\n  readonly fragmentMap?: FragmentMap;\n  // General-purpose deep-merge function for use during writes.\n  merge<T>(existing: T, incoming: T): T;\n};\n\ninterface ProcessSelectionSetOptions {\n  dataId?: string,\n  result: Record<string, any>;\n  selectionSet: SelectionSetNode;\n  context: WriteContext;\n  mergeTree: MergeTree;\n}\n\nexport interface WriteToStoreOptions {\n  query: DocumentNode;\n  result: Object;\n  dataId?: string;\n  store: NormalizedCache;\n  variables?: Object;\n}\n\nexport class StoreWriter {\n  constructor(\n    public readonly cache: InMemoryCache,\n    private reader?: StoreReader,\n  ) {}\n\n  /**\n   * Writes the result of a query to the store.\n   *\n   * @param result The result object returned for the query document.\n   *\n   * @param query The query document whose result we are writing to the store.\n   *\n   * @param store The {@link NormalizedCache} used by Apollo for the `data` portion of the store.\n   *\n   * @param variables A map from the name of a variable to its value. These variables can be\n   * referenced by the query document.\n   *\n   * @return A `Reference` to the written object.\n   */\n  public writeToStore({\n    query,\n    result,\n    dataId,\n    store,\n    variables,\n  }: WriteToStoreOptions): Reference | undefined {\n    const operationDefinition = getOperationDefinition(query)!;\n    const merger = makeProcessedFieldsMerger();\n\n    variables = {\n      ...getDefaultValues(operationDefinition),\n      ...variables!,\n    };\n\n    const ref = this.processSelectionSet({\n      result: result || Object.create(null),\n      dataId,\n      selectionSet: operationDefinition.selectionSet,\n      mergeTree: { map: new Map },\n      context: {\n        store,\n        written: Object.create(null),\n        merge<T>(existing: T, incoming: T) {\n          return merger.merge(existing, incoming) as T;\n        },\n        variables,\n        varString: JSON.stringify(variables),\n        fragmentMap: createFragmentMap(getFragmentDefinitions(query)),\n      },\n    });\n\n    if (!isReference(ref)) {\n      throw new InvariantError(`Could not identify object ${JSON.stringify(result)}`);\n    }\n\n    // Any IDs written explicitly to the cache will be retained as\n    // reachable root IDs for garbage collection purposes. Although this\n    // logic includes root IDs like ROOT_QUERY and ROOT_MUTATION, their\n    // retainment counts are effectively ignored because cache.gc() always\n    // includes them in its root ID set.\n    store.retain(ref.__ref);\n\n    return ref;\n  }\n\n  private processSelectionSet({\n    dataId,\n    result,\n    selectionSet,\n    context,\n    // This object allows processSelectionSet to report useful information\n    // to its callers without explicitly returning that information.\n    mergeTree,\n  }: ProcessSelectionSetOptions): StoreObject | Reference {\n    const { policies } = this.cache;\n\n    // Identify the result object, even if dataId was already provided,\n    // since we always need keyObject below.\n    const [id, keyObject] = policies.identify(\n      result, selectionSet, context.fragmentMap);\n\n    // If dataId was not provided, fall back to the id just generated by\n    // policies.identify.\n    dataId = dataId || id;\n\n    if (\"string\" === typeof dataId) {\n      // Avoid processing the same entity object using the same selection\n      // set more than once. We use an array instead of a Set since most\n      // entity IDs will be written using only one selection set, so the\n      // size of this array is likely to be very small, meaning indexOf is\n      // likely to be faster than Set.prototype.has.\n      const sets = context.written[dataId] || (context.written[dataId] = []);\n      const ref = makeReference(dataId);\n      if (sets.indexOf(selectionSet) >= 0) return ref;\n      sets.push(selectionSet);\n\n      // If we're about to write a result object into the store, but we\n      // happen to know that the exact same (===) result object would be\n      // returned if we were to reread the result with the same inputs,\n      // then we can skip the rest of the processSelectionSet work for\n      // this object, and immediately return a Reference to it.\n      if (this.reader && this.reader.isFresh(\n        result,\n        ref,\n        selectionSet,\n        context,\n      )) {\n        return ref;\n      }\n    }\n\n    // This variable will be repeatedly updated using context.merge to\n    // accumulate all fields that need to be written into the store.\n    let incomingFields: StoreObject = Object.create(null);\n\n    // Write any key fields that were used during identification, even if\n    // they were not mentioned in the original query.\n    if (keyObject) {\n      incomingFields = context.merge(incomingFields, keyObject);\n    }\n\n    // If typename was not passed in, infer it. Note that typename is\n    // always passed in for tricky-to-infer cases such as \"Query\" for\n    // ROOT_QUERY.\n    const typename: string | undefined =\n      (dataId && policies.rootTypenamesById[dataId]) ||\n      getTypenameFromResult(result, selectionSet, context.fragmentMap) ||\n      (dataId && context.store.get(dataId, \"__typename\") as string);\n\n    if (\"string\" === typeof typename) {\n      incomingFields.__typename = typename;\n    }\n\n    const workSet = new Set(selectionSet.selections);\n\n    workSet.forEach(selection => {\n      if (!shouldInclude(selection, context.variables)) return;\n\n      if (isField(selection)) {\n        const resultFieldKey = resultKeyNameFromField(selection);\n        const value = result[resultFieldKey];\n\n        if (typeof value !== 'undefined') {\n          const storeFieldName = policies.getStoreFieldName({\n            typename,\n            fieldName: selection.name.value,\n            field: selection,\n            variables: context.variables,\n          });\n\n          const childTree = getChildMergeTree(mergeTree, storeFieldName);\n\n          let incomingValue =\n            this.processFieldValue(value, selection, context, childTree);\n\n          const childTypename = selection.selectionSet\n            && context.store.getFieldValue<string>(incomingValue as StoreObject, \"__typename\")\n            || void 0;\n\n          const merge = policies.getMergeFunction(\n            typename,\n            selection.name.value,\n            childTypename,\n          );\n\n          if (merge) {\n            childTree.info = {\n              // TODO Check compatibility against any existing\n              // childTree.field?\n              field: selection,\n              typename,\n              merge,\n            };\n          } else {\n            maybeRecycleChildMergeTree(mergeTree, storeFieldName);\n          }\n\n          incomingFields = context.merge(incomingFields, {\n            [storeFieldName]: incomingValue,\n          });\n\n        } else if (\n          policies.usingPossibleTypes &&\n          !hasDirectives([\"defer\", \"client\"], selection)\n        ) {\n          throw new InvariantError(\n            `Missing field '${resultFieldKey}' in ${JSON.stringify(\n              result,\n              null,\n              2,\n            ).substring(0, 100)}`,\n          );\n        }\n      } else {\n        // This is not a field, so it must be a fragment, either inline or named\n        const fragment = getFragmentFromSelection(\n          selection,\n          context.fragmentMap,\n        );\n\n        if (fragment &&\n            // By passing result and context.variables, we enable\n            // policies.fragmentMatches to bend the rules when typename is\n            // not a known subtype of the fragment type condition, but the\n            // result object contains all the keys requested by the\n            // fragment, which strongly suggests the fragment probably\n            // matched. This fuzzy matching behavior must be enabled by\n            // including a regular expression string (such as \".*\" or\n            // \"Prefix.*\" or \".*Suffix\") in the possibleTypes array for\n            // specific supertypes; otherwise, all matching remains exact.\n            // Fuzzy matches are remembered by the Policies object and\n            // later used when reading from the cache. Since there is no\n            // incoming result object to check when reading, reading does\n            // not involve the same fuzzy inference, so the StoreReader\n            // class calls policies.fragmentMatches without passing result\n            // or context.variables. The flexibility of fuzzy matching\n            // allows existing clients to accommodate previously unknown\n            // __typename strings produced by server/schema changes, which\n            // would otherwise be breaking changes.\n            policies.fragmentMatches(fragment, typename, result, context.variables)) {\n          fragment.selectionSet.selections.forEach(workSet.add, workSet);\n        }\n      }\n    });\n\n    if (\"string\" === typeof dataId) {\n      const entityRef = makeReference(dataId);\n\n      if (mergeTree.map.size) {\n        incomingFields = this.applyMerges(mergeTree, entityRef, incomingFields, context);\n      }\n\n      if (process.env.NODE_ENV !== \"production\") {\n        const hasSelectionSet = (storeFieldName: string) =>\n          fieldsWithSelectionSets.has(fieldNameFromStoreName(storeFieldName));\n        const fieldsWithSelectionSets = new Set<string>();\n        workSet.forEach(selection => {\n          if (isField(selection) && selection.selectionSet) {\n            fieldsWithSelectionSets.add(selection.name.value);\n          }\n        });\n\n        const hasMergeFunction = (storeFieldName: string) => {\n          const childTree = mergeTree.map.get(storeFieldName);\n          return Boolean(childTree && childTree.info && childTree.info.merge);\n        };\n\n        Object.keys(incomingFields).forEach(storeFieldName => {\n          // If a merge function was defined for this field, trust that it\n          // did the right thing about (not) clobbering data. If the field\n          // has no selection set, it's a scalar field, so it doesn't need\n          // a merge function (even if it's an object, like JSON data).\n          if (hasSelectionSet(storeFieldName) &&\n              !hasMergeFunction(storeFieldName)) {\n            warnAboutDataLoss(\n              entityRef,\n              incomingFields,\n              storeFieldName,\n              context.store,\n            );\n          }\n        });\n      }\n\n      context.store.merge(dataId, incomingFields);\n\n      return entityRef;\n    }\n\n    return incomingFields;\n  }\n\n  private processFieldValue(\n    value: any,\n    field: FieldNode,\n    context: WriteContext,\n    mergeTree: MergeTree,\n  ): StoreValue {\n    if (!field.selectionSet || value === null) {\n      // In development, we need to clone scalar values so that they can be\n      // safely frozen with maybeDeepFreeze in readFromStore.ts. In production,\n      // it's cheaper to store the scalar values directly in the cache.\n      return process.env.NODE_ENV === 'production' ? value : cloneDeep(value);\n    }\n\n    if (Array.isArray(value)) {\n      return value.map((item, i) => {\n        const value = this.processFieldValue(\n          item, field, context, getChildMergeTree(mergeTree, i));\n        maybeRecycleChildMergeTree(mergeTree, i);\n        return value;\n      });\n    }\n\n    return this.processSelectionSet({\n      result: value,\n      selectionSet: field.selectionSet,\n      context,\n      mergeTree,\n    });\n  }\n\n  private applyMerges<T extends StoreValue>(\n    mergeTree: MergeTree,\n    existing: StoreValue,\n    incoming: T,\n    context: ReadMergeModifyContext,\n    getStorageArgs?: Parameters<EntityStore[\"getStorage\"]>,\n  ): T {\n    if (mergeTree.map.size && !isReference(incoming)) {\n      const e: StoreObject | Reference | undefined = (\n        // Items in the same position in different arrays are not\n        // necessarily related to each other, so when incoming is an array\n        // we process its elements as if there was no existing data.\n        !Array.isArray(incoming) &&\n        // Likewise, existing must be either a Reference or a StoreObject\n        // in order for its fields to be safe to merge with the fields of\n        // the incoming object.\n        (isReference(existing) || storeValueIsStoreObject(existing))\n      ) ? existing : void 0;\n\n      // This narrowing is implied by mergeTree.map.size > 0 and\n      // !isReference(incoming), though TypeScript understandably cannot\n      // hope to infer this type.\n      const i = incoming as StoreObject | StoreValue[];\n\n      // The options.storage objects provided to read and merge functions\n      // are derived from the identity of the parent object plus a\n      // sequence of storeFieldName strings/numbers identifying the nested\n      // field name path of each field value to be merged.\n      if (e && !getStorageArgs) {\n        getStorageArgs = [isReference(e) ? e.__ref : e];\n      }\n\n      // It's possible that applying merge functions to this subtree will\n      // not change the incoming data, so this variable tracks the fields\n      // that did change, so we can create a new incoming object when (and\n      // only when) at least one incoming field has changed. We use a Map\n      // to preserve the type of numeric keys.\n      let changedFields: Map<string | number, StoreValue> | undefined;\n\n      const getValue = (\n        from: typeof e | typeof i,\n        name: string | number,\n      ): StoreValue => {\n        return Array.isArray(from)\n          ? (typeof name === \"number\" ? from[name] : void 0)\n          : context.store.getFieldValue(from, String(name))\n      };\n\n      mergeTree.map.forEach((childTree, storeFieldName) => {\n        if (getStorageArgs) {\n          getStorageArgs.push(storeFieldName);\n        }\n        const eVal = getValue(e, storeFieldName);\n        const iVal = getValue(i, storeFieldName);\n        const aVal = this.applyMerges(\n          childTree,\n          eVal,\n          iVal,\n          context,\n          getStorageArgs,\n        );\n        if (aVal !== iVal) {\n          changedFields = changedFields || new Map;\n          changedFields.set(storeFieldName, aVal);\n        }\n        if (getStorageArgs) {\n          invariant(getStorageArgs.pop() === storeFieldName);\n        }\n      });\n\n      if (changedFields) {\n        // Shallow clone i so we can add changed fields to it.\n        incoming = (Array.isArray(i) ? i.slice(0) : { ...i }) as T;\n        changedFields.forEach((value, name) => {\n          (incoming as any)[name] = value;\n        });\n      }\n    }\n\n    if (mergeTree.info) {\n      return this.cache.policies.runMergeFunction(\n        existing,\n        incoming,\n        mergeTree.info,\n        context,\n        getStorageArgs && context.store.getStorage(...getStorageArgs),\n      );\n    }\n\n    return incoming;\n  }\n}\n\nconst emptyMergeTreePool: MergeTree[] = [];\n\nfunction getChildMergeTree(\n  { map }: MergeTree,\n  name: string | number,\n): MergeTree {\n  if (!map.has(name)) {\n    map.set(name, emptyMergeTreePool.pop() || { map: new Map });\n  }\n  return map.get(name)!;\n}\n\nfunction maybeRecycleChildMergeTree(\n  { map }: MergeTree,\n  name: string | number,\n) {\n  const childTree = map.get(name);\n  if (childTree &&\n      !childTree.info &&\n      !childTree.map.size) {\n    emptyMergeTreePool.push(childTree);\n    map.delete(name);\n  }\n}\n\nconst warnings = new Set<string>();\n\n// Note that this function is unused in production, and thus should be\n// pruned by any well-configured minifier.\nfunction warnAboutDataLoss(\n  existingRef: Reference,\n  incomingObj: StoreObject,\n  storeFieldName: string,\n  store: NormalizedCache,\n) {\n  const getChild = (objOrRef: StoreObject | Reference): StoreObject | false => {\n    const child = store.getFieldValue<StoreObject>(objOrRef, storeFieldName);\n    return typeof child === \"object\" && child;\n  };\n\n  const existing = getChild(existingRef);\n  if (!existing) return;\n\n  const incoming = getChild(incomingObj);\n  if (!incoming) return;\n\n  // It's always safe to replace a reference, since it refers to data\n  // safely stored elsewhere.\n  if (isReference(existing)) return;\n\n  // If the values are structurally equivalent, we do not need to worry\n  // about incoming replacing existing.\n  if (equal(existing, incoming)) return;\n\n  // If we're replacing every key of the existing object, then the\n  // existing data would be overwritten even if the objects were\n  // normalized, so warning would not be helpful here.\n  if (Object.keys(existing).every(\n    key => store.getFieldValue(incoming, key) !== void 0)) {\n    return;\n  }\n\n  const parentType =\n    store.getFieldValue<string>(existingRef, \"__typename\") ||\n    store.getFieldValue<string>(incomingObj, \"__typename\");\n  const fieldName = fieldNameFromStoreName(storeFieldName);\n  const typeDotName = `${parentType}.${fieldName}`;\n  // Avoid warning more than once for the same type and field name.\n  if (warnings.has(typeDotName)) return;\n  warnings.add(typeDotName);\n\n  const childTypenames: string[] = [];\n  // Arrays do not have __typename fields, and always need a custom merge\n  // function, even if their elements are normalized entities.\n  if (!Array.isArray(existing) &&\n      !Array.isArray(incoming)) {\n    [existing, incoming].forEach(child => {\n      const typename = store.getFieldValue(child, \"__typename\");\n      if (typeof typename === \"string\" &&\n          !childTypenames.includes(typename)) {\n        childTypenames.push(typename);\n      }\n    });\n  }\n\n  invariant.warn(\n`Cache data may be lost when replacing the ${fieldName} field of a ${parentType} object.\n\nTo address this problem (which is not a bug in Apollo Client), ${\n  childTypenames.length\n    ? \"either ensure all objects of type \" +\n        childTypenames.join(\" and \") + \" have an ID or a custom merge function, or \"\n    : \"\"\n}define a custom merge function for the ${\n  typeDotName\n} field, so InMemoryCache can safely merge these objects:\n\n  existing: ${JSON.stringify(existing).slice(0, 1000)}\n  incoming: ${JSON.stringify(incoming).slice(0, 1000)}\n\nFor more information about these options, please refer to the documentation:\n\n  * Ensuring entity objects have IDs: https://go.apollo.dev/c/generating-unique-identifiers\n  * Defining custom merge functions: https://go.apollo.dev/c/merging-non-normalized-objects\n`);\n}\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}